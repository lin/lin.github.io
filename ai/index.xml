<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>《论智力》 on Yingkui</title><link>https://albert.cn/ai/</link><description>Recent content in 《论智力》 on Yingkui</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© Copyright albert.cn / Yingkui.com All Rights Reserved</copyright><atom:link href="https://albert.cn/ai/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://albert.cn/ai/learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://albert.cn/ai/learning/</guid><description>The nature of teaching For each information vector $v$, we have a list of transformation matrix $m_i$ with force weight $w_i$ as how hard it is to retrieve from the database, so that we can get new information vectors $u_i$.
For a known space, the educator has been trained with lots of data, so he/she knows the $v \rightarrow m_i$ beforehand, the task for he/she is to train a new learner this relationships in a short period of time.</description></item><item><title/><link>https://albert.cn/ai/outline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://albert.cn/ai/outline/</guid><description>Outline preface
Computation Distinguishability Composition Transformation Max Computation Freedom (Solving Boundary, Fundamental Limitation) Meta-Computation (Facts beyond deterministic) Reverse Computation Abstraction Top-Down Bottom-Up Accumulation of Same Objects Probability: the Indistinguishable Incomplete Information Computation with Abstraction Solving by Searching Guessing by Searching Nearby First Reduction by Computed Result Reduction by Abstract Computed Result Learning without Specific Goals Remembering Object Remember the experienced distinguishable objects Remembering Association Remembering Pattern Generic Solving Algorithm The Robustness v.</description></item><item><title/><link>https://albert.cn/ai/preface/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://albert.cn/ai/preface/</guid><description>Preface The necessity of Turing complete, but not its completeness.
To do all possible computations, we need freedoms that include a few for-all sentences.
The ability to distinguish (has boundary) The ability to recognize The ability to reproduce The ability to use internal representations Access its neighbors freely. Store information freely. The ability to distinguish stuffs is the most fundamental ability for any intelligent agents.
All it cares is that these two objects are different.</description></item><item><title/><link>https://albert.cn/ai/random/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://albert.cn/ai/random/</guid><description>随想 对我来说，一个比较困难的问题就是，如何把反复出现的信号A和反复出现的转化函数B进行chunkify。
具体怎么实现我是不知道的，但人脑应该是可以实现任意的可区分信号和可区分转化函数之间的随意链接
也就是说，可区分信号，和可区分转化函数都是简单的元素所组成的，如何把这些简单的元素组合作为一个单一的独立的信号，我是不清楚的。
各处都原子化是唯一路径，线性的拟合以及GPU的使用，就是最终正确的道路</description></item><item><title>1.1 Distinguishability</title><link>https://albert.cn/ai/1-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://albert.cn/ai/1-1/</guid><description>It seems to me that I am rewriting Turing’s paper in a new perspective. The whole first chapter is to reclaim Turing’s idea, but in a way to discuss its necessity but not its completeness. The set of Turing’s abilities is the subset of the total abilities. Distinguishability is</description></item></channel></rss>