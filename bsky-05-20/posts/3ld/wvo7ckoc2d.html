<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Yingkui: "之所以大模型的输出会让 Musk 难受，是因为大模型中权重更高的高质量的训练数据来自于书籍文章博文论文，甚至可以说是这些高质量的有逻辑的文字，才使得大模型更容易变得“智慧”。而那些前后矛盾，不知所云的文字，简直就是幻觉垃圾场，污染数据。

那因此大模型所表现的就更接近于高认知、受过良好教育、摄取更多信息的群体所集体涌现出的观点。与 GPT 聊天，就会有种 与君一席话，胜读十年书。如果 GPT 的数据都是来自 微博小红书，都能把人逼疯"</title><link rel=stylesheet href="../../assets/style.css"><meta property=og:title content="Yingkui (@yingkui.com)"><meta property=og:description content="之所以大模型的输出会让 Musk 难受，是因为大模型中权重更高的高质量的训练数据来自于书籍文章博文论文，甚至可以说是这些高质量的有逻辑的文字，才使得大模型更容易变得“智慧”。而那些前后矛盾，不知所云的文字，简直就是幻觉垃圾场，污染数据。

那因此大模型所表现的就更接近于高认知、受过良好教育、摄取更多信息的群体所集体涌现出的观点。与 GPT 聊天，就会有种 与君一席话，胜读十年书。如果 GPT 的数据都是来自 微博小红书，都能把人逼疯"></head><body><div class=Root><div class=Page><div class=PageHeader><a href="../../index.html" class=Link>Home</a><a href="../../timeline/posts/1.html" class=Link>Timeline</a><a href="../../search.html" class=Link>Search</a></div><div class=PermalinkPost><div class=PermalinkPost__header><div class=PermalinkPost__avatarContainer><img loading=lazy src="../../blobs/bafkreih/62wkfwoeqra62rwzq4wxb5ifhmkbuoyjnwwdilpdpn2obzuuofq" class=PermalinkPost__avatar></div><span class=PermalinkPost__nameContainer><bdi class=PermalinkPost__displayNameContainer><span class=PermalinkPost__displayName>Yingkui</span></bdi><span class=PermalinkPost__handle>@yingkui.com</span></span></div><div class=PermalinkPost__body>之所以大模型的输出会让 Musk 难受，是因为大模型中权重更高的高质量的训练数据来自于书籍文章博文论文，甚至可以说是这些高质量的有逻辑的文字，才使得大模型更容易变得“智慧”。而那些前后矛盾，不知所云的文字，简直就是幻觉垃圾场，污染数据。

那因此大模型所表现的就更接近于高认知、受过良好教育、摄取更多信息的群体所集体涌现出的观点。与 GPT 聊天，就会有种 与君一席话，胜读十年书。如果 GPT 的数据都是来自 微博小红书，都能把人逼疯</div><div class=PermalinkPost__footer><time datetime="2024-12-23T02:39:37.317Z" class=PermalinkPost__date>December 23, 2024 at 10:39 AM</time></div></div><hr><div class=ThreadPage__descendants></div></div></div></body></html>