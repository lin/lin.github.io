<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Yingkui: "学习其实就是降低 bite-size 的熵值

那么像大模型或者贝叶斯修正分布所需要的遍数有多少

每次为什么能够增加或降低权重

消耗的能力，得到的奖励是什么"</title><link rel=stylesheet href="../../assets/style.css"><meta property=og:title content="Yingkui (@yingkui.com)"><meta property=og:description content="学习其实就是降低 bite-size 的熵值

那么像大模型或者贝叶斯修正分布所需要的遍数有多少

每次为什么能够增加或降低权重

消耗的能力，得到的奖励是什么"></head><body><div class=Root><div class=Page><div class=PageHeader><a href="../../index.html" class=Link>Home</a><a href="../../timeline/posts/1.html" class=Link>Timeline</a><a href="../../search.html" class=Link>Search</a></div><div class=PermalinkPost><div class=PermalinkPost__header><div class=PermalinkPost__avatarContainer><img loading=lazy src="../../blobs/bafkreih/62wkfwoeqra62rwzq4wxb5ifhmkbuoyjnwwdilpdpn2obzuuofq" class=PermalinkPost__avatar></div><span class=PermalinkPost__nameContainer><bdi class=PermalinkPost__displayNameContainer><span class=PermalinkPost__displayName>Yingkui</span></bdi><span class=PermalinkPost__handle>@yingkui.com</span></span></div><div class=PermalinkPost__body>学习其实就是降低 bite-size 的熵值

那么像大模型或者贝叶斯修正分布所需要的遍数有多少

每次为什么能够增加或降低权重

消耗的能力，得到的奖励是什么</div><div class=PermalinkPost__footer><time datetime="2025-05-22T09:05:05.914Z" class=PermalinkPost__date>May 22, 2025 at 5:05 PM</time></div></div><hr><div class=ThreadPage__descendants></div></div></div></body></html>