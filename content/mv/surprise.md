### 新词

FEP says: any system (like a brain) must minimize surprise (prediction error) by updating its internal model of the world.

To do that, it builds latent representations (hidden states) that explain incoming sensations and signals.

In humans, these latent states are often expressed through concepts and words

A new lexeme in science/economics (say “inflation”) is not just a word, but a chunked model of patterns in the world:

Before: the student sees prices rising, wages shifting, government printing money, but all feels disconnected → high surprise, fragmented predictions.

After: with the lexeme “inflation,” the student compresses these events into one causal, generative explanation → surprise is reduced.

So a lexeme acts like a low-energy boundary condition (a Markov blanket for meaning).

Benefits in Terms of FEP

Lower Prediction Error

Once you learn “inflation,” your brain can predict price movements, news, policies with less confusion.

This reduces the free energy associated with interpreting economics signals.

Improved Generative Model

A lexeme is like adding a new latent variable into your internal Bayesian model.

This allows you to simulate and forecast future states more accurately.

Compression / Efficiency

Instead of storing 100 separate facts, you now bundle them under one compressed representation.

This saves cognitive resources, freeing up capacity for higher-level reasoning.

Action Guidance

With the concept of “inflation,” you know not to keep cash idle during high inflation.

Lexemes reduce uncertainty in deciding what action minimizes expected surprise.

Learning a lexeme is like to write a funciton in your brain, you just call the function “inflation()” → and get a quick, structured response.

Learning a new lexeme under the Free Energy Principle gives you a compressed, generative model that reduces prediction error, increases efficiency, and helps you act adaptively.


Latent variable in Bayesian terms = something hidden that explains your observations.

Lexeme = a compressed representation of such a hidden structure, which you can use to make sense of otherwise messy signals.

1. If Learned in School (structured)

The teacher gives you the lexeme (e.g., “inflation”), a clean definition, and examples.

This is like someone telling you directly: “here’s the latent variable that explains these observations.”

It saves you time and reduces trial-and-error learning.

You get to “install” the latent variable into your model quickly and align with the shared cultural/scientific framework.

If Not Learned in School (self-discovery)

You still encounter phenomena: prices rising, wages lagging, currency changes.

Without the label “inflation,” you struggle to unify them.

Eventually, you might invent your own internal lexeme, like “money rot” or “price sickness.”

Functionally, your brain is still searching for a hidden variable that reduces prediction error.

This is a more expensive route in terms of free energy minimization because:

You may take longer to notice the pattern.

Your invented concept may not match society’s shared lexeme, so communication costs rise.

You risk misgeneralizing (e.g., thinking “price sickness” is caused by merchants’ greed, not by macroeconomic forces).

Why Lexemes Are So Valuable

They are cultural priors: pre-compressed latent variables that others have already tested.

When you adopt them, you shortcut the painful process of discovering them on your own.

In Bayesian language: you’re inheriting a well-shaped prior distribution that reduces your personal free energy much faster.

Sometimes if you don’t get the lexeme from school (or other cultural sources), your brain may never actually converge on the right latent variable.

Why That Happens

Too much noise: The raw experiences are messy. Without the right compression, you can’t see the hidden structure.

Local explanations: The brain will “patch” things with folk explanations (e.g., “merchants are greedy” instead of “inflation is happening”).

Missed abstraction level: Some lexemes live at a very high abstraction (like “entropy” in physics). Without exposure, you may never invent it, because you’d need thousands of observations across domains.

Free Energy Perspective

Your generative model never gets upgraded with that latent variable.

That means your predictions remain noisy, error-prone, and costly.

You live in a world where surprise keeps accumulating, because you lack the compressed concept that would explain away the variation.

This is like running an algorithm without the right feature space: you keep overfitting to noise.

Real-World Examples

Economics:
Without “inflation” as a lexeme, a person might think “money just randomly loses value” or “shopkeepers are cheating.” They never see the systemic cause.

Biology:
Without the lexeme “germ theory,” people thought disease came from “bad air” or curses. Many never figured it out without schooling.

Physics:
Without “energy conservation,” phenomena like motion and heat stay mysterious. A craftsman may work with machines daily but never grasp why perpetual motion machines can’t exist.

Cultural Transmission as Energy Saver

That’s why education and culture are energy-saving machines.

They give you ready-made lexemes (latent variables) that humans couldn’t invent alone in a single lifetime.

Without them, you risk staying trapped in folk theories, never reaching the right model, no matter how much personal experience you have