<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>- Yingkui Lin</title><meta name=viewport content="width=device-width,initial-scale=1">
<meta itemprop=name content="Yingkui Lin"><meta itemprop=description content="4.4 对验收材料的改良 教学材料的好坏，是在同等算力下，学习者得到的信息值多寡
验收材料的好坏，是在同等算法下，测试者得到的信息值多寡
不要为了区分，而难为学生；要为了传播知识，而激励学生
对于不同的考试，我们自然并不会使用一样的要求标准。
对于一个资格性的考试，应该更多的侧重于对必备技能的考察，对知识储备的检测，对关联熟练度的考察。
对于一个选拔性的考试，尤其是类似中国高考这样，要对学生解决问题的能力进行区分的考试，应当考察学生解决问题中对通用策略的使用，逐步的增加难度，可以是必备技能的一种变形转化，或者是多个技能的结合应用，也可能是一个需要探索尝试的创新情景。
但与此同时，类似高考这样的考试，有着教学指挥棒的作用，应当为了提高知识的普及率，加大资格性考察的比例，让学生学有所得，有的放矢。可以开源题目库，甚至是开源生成考题的算法，这样的好处，有利于整体学生知识储备和思维能力的改善，而不是为了选拔，放弃了促进整体认知能力提升的功效。
而本节所谓的改良，就是希望验收材料，要让考生更有信心，有努力的方向，有努力后获得技能的成就反馈，而不是为了区分而一味的难为学生，考察频率低、通用性弱的技能。
也正如前节所述，过多的弱信号、弱策略、窄入口的考察，无法区分学生在某一领域的熟悉度和解决问题的半径，无法区分学生在某一领域内投入精力的多寡，从而为进一步学习或者解决相关问题提供足够的信息依据。
4.4.1 技能考察对技能结构的影响 我们可以假想这样一套考题，
这个考题的覆盖面广，横跨十几个学科，计算机科学，生物学，历史，微积分，地理
而且考察的每一道题，都是在100个需要较长训练时间的技能中随机抽取一个
其难度，是可想而知的，对于一个考生来说，是很难准备这样的一个考试的。
但现实生活中，我们并不会经常遇到这样的场景，但如果考题出的很难，就会变成一个辐射型的技能关系，也就是说一个技能的学习，并不能为你解决另外一个技能提供太多帮助，例如，下图所示的知识结构：
对于这种辐射型的技能，如果每一个点训练时长有限，那么训练的回报率还可以接受。但如果，每一个技能的训练周期很长，就会导致训练的回报率变得很低，会极大地增加学生的挫败感。
但如果命题者，总是考察低频的外环的技能，而不考察中间的可以简化的技能，可以认为是作为命题的一种失误。一来，造成学生备考中的一种混乱，过高的门槛将学生拒之门外，二来，评价缺乏区分度，使得学生要进行大量的训练时长之后，才能体验到学有所成的成就感。但和之前所描述的硬拔式教育相同，虽然对于一个学习能力很强的学生，可能设置这样一个困难的挑战，会加快TA对技能的遍历，但作为一个为普遍学生群体提供内容的教学者来说，这么做是不负责任的。
混乱和随意是不需费力的，但秩序和结构却是要用心和动脑的
对于一个出色的命题，应该对于学生基本技能的掌握有所考察和体现，从基于工具的角度，对基本技能周边可以探索和转化的技能，应当有所侧重，而减少零散的，特例化的技能的考察。如果对考察频率进行分析，绘制出技能的关系图，技能节点间关联度较高的关系图，一个训练回报率合理的技能分布，应该是命题人追求的目标，而不是简单的、粗暴的追求区分，甚至达到了刁难学生的地步。如果想难为学生，并不是一件困难的事；但如何一石多鸟的达到激励、考察和区分的题目，才是需要大量智力投入的。
考试是为了区分能力，不是为了区分分数
对于一个不太出色的命题，会造成评价上的低效，也就是说，无法区分和识别一个掌握了相应技能的学生（算法），有如一个机器学习的测试样本和训练样本相差甚远，那么机器学习所生产出的算法就无法判断其高效性。也就是说，从测试目的出发，测试效率很低。
对于一个考试题目，我们应该对其进行信息量分析。
【案例】低信息量的试题 若 $\ln (x+1) \leqslant ax$， $ab^2 - 2b + 1 = 0$ ，求 $b$
这样一道试题，结合了一元二次方程和导数，但是因为求 $a$ 的本身难度很大，使得这个题目难以识别一个学生是否掌握了一元二次方程。
教育的目的是为了让学习者更高效、更有学习动力的提高自我，粗糙的验收材料，和粗糙的教学材料一样，可能会阻碍教育目的的达到。
对于教学材料的制作和评价，和对验收材料的制作和评价，应该是相对独立进行分析的。
通用能力的考察 未来学习场景的模拟"><meta itemprop=wordCount content="47"><meta property="og:url" content="https://yingkui.com/edu/4-4/"><meta property="og:site_name" content="Yingkui Lin"><meta property="og:title" content="Yingkui Lin"><meta property="og:description" content="4.4 对验收材料的改良 教学材料的好坏，是在同等算力下，学习者得到的信息值多寡
验收材料的好坏，是在同等算法下，测试者得到的信息值多寡
不要为了区分，而难为学生；要为了传播知识，而激励学生
对于不同的考试，我们自然并不会使用一样的要求标准。
对于一个资格性的考试，应该更多的侧重于对必备技能的考察，对知识储备的检测，对关联熟练度的考察。
对于一个选拔性的考试，尤其是类似中国高考这样，要对学生解决问题的能力进行区分的考试，应当考察学生解决问题中对通用策略的使用，逐步的增加难度，可以是必备技能的一种变形转化，或者是多个技能的结合应用，也可能是一个需要探索尝试的创新情景。
但与此同时，类似高考这样的考试，有着教学指挥棒的作用，应当为了提高知识的普及率，加大资格性考察的比例，让学生学有所得，有的放矢。可以开源题目库，甚至是开源生成考题的算法，这样的好处，有利于整体学生知识储备和思维能力的改善，而不是为了选拔，放弃了促进整体认知能力提升的功效。
而本节所谓的改良，就是希望验收材料，要让考生更有信心，有努力的方向，有努力后获得技能的成就反馈，而不是为了区分而一味的难为学生，考察频率低、通用性弱的技能。
也正如前节所述，过多的弱信号、弱策略、窄入口的考察，无法区分学生在某一领域的熟悉度和解决问题的半径，无法区分学生在某一领域内投入精力的多寡，从而为进一步学习或者解决相关问题提供足够的信息依据。
4.4.1 技能考察对技能结构的影响 我们可以假想这样一套考题，
这个考题的覆盖面广，横跨十几个学科，计算机科学，生物学，历史，微积分，地理
而且考察的每一道题，都是在100个需要较长训练时间的技能中随机抽取一个
其难度，是可想而知的，对于一个考生来说，是很难准备这样的一个考试的。
但现实生活中，我们并不会经常遇到这样的场景，但如果考题出的很难，就会变成一个辐射型的技能关系，也就是说一个技能的学习，并不能为你解决另外一个技能提供太多帮助，例如，下图所示的知识结构：
对于这种辐射型的技能，如果每一个点训练时长有限，那么训练的回报率还可以接受。但如果，每一个技能的训练周期很长，就会导致训练的回报率变得很低，会极大地增加学生的挫败感。
但如果命题者，总是考察低频的外环的技能，而不考察中间的可以简化的技能，可以认为是作为命题的一种失误。一来，造成学生备考中的一种混乱，过高的门槛将学生拒之门外，二来，评价缺乏区分度，使得学生要进行大量的训练时长之后，才能体验到学有所成的成就感。但和之前所描述的硬拔式教育相同，虽然对于一个学习能力很强的学生，可能设置这样一个困难的挑战，会加快TA对技能的遍历，但作为一个为普遍学生群体提供内容的教学者来说，这么做是不负责任的。
混乱和随意是不需费力的，但秩序和结构却是要用心和动脑的
对于一个出色的命题，应该对于学生基本技能的掌握有所考察和体现，从基于工具的角度，对基本技能周边可以探索和转化的技能，应当有所侧重，而减少零散的，特例化的技能的考察。如果对考察频率进行分析，绘制出技能的关系图，技能节点间关联度较高的关系图，一个训练回报率合理的技能分布，应该是命题人追求的目标，而不是简单的、粗暴的追求区分，甚至达到了刁难学生的地步。如果想难为学生，并不是一件困难的事；但如何一石多鸟的达到激励、考察和区分的题目，才是需要大量智力投入的。
考试是为了区分能力，不是为了区分分数
对于一个不太出色的命题，会造成评价上的低效，也就是说，无法区分和识别一个掌握了相应技能的学生（算法），有如一个机器学习的测试样本和训练样本相差甚远，那么机器学习所生产出的算法就无法判断其高效性。也就是说，从测试目的出发，测试效率很低。
对于一个考试题目，我们应该对其进行信息量分析。
【案例】低信息量的试题 若 $\ln (x+1) \leqslant ax$， $ab^2 - 2b + 1 = 0$ ，求 $b$
这样一道试题，结合了一元二次方程和导数，但是因为求 $a$ 的本身难度很大，使得这个题目难以识别一个学生是否掌握了一元二次方程。
教育的目的是为了让学习者更高效、更有学习动力的提高自我，粗糙的验收材料，和粗糙的教学材料一样，可能会阻碍教育目的的达到。
对于教学材料的制作和评价，和对验收材料的制作和评价，应该是相对独立进行分析的。
通用能力的考察 未来学习场景的模拟"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="edu"><meta name=twitter:card content="summary"><meta name=twitter:title content="Yingkui Lin"><meta name=twitter:description content="4.4 对验收材料的改良 教学材料的好坏，是在同等算力下，学习者得到的信息值多寡
验收材料的好坏，是在同等算法下，测试者得到的信息值多寡
不要为了区分，而难为学生；要为了传播知识，而激励学生
对于不同的考试，我们自然并不会使用一样的要求标准。
对于一个资格性的考试，应该更多的侧重于对必备技能的考察，对知识储备的检测，对关联熟练度的考察。
对于一个选拔性的考试，尤其是类似中国高考这样，要对学生解决问题的能力进行区分的考试，应当考察学生解决问题中对通用策略的使用，逐步的增加难度，可以是必备技能的一种变形转化，或者是多个技能的结合应用，也可能是一个需要探索尝试的创新情景。
但与此同时，类似高考这样的考试，有着教学指挥棒的作用，应当为了提高知识的普及率，加大资格性考察的比例，让学生学有所得，有的放矢。可以开源题目库，甚至是开源生成考题的算法，这样的好处，有利于整体学生知识储备和思维能力的改善，而不是为了选拔，放弃了促进整体认知能力提升的功效。
而本节所谓的改良，就是希望验收材料，要让考生更有信心，有努力的方向，有努力后获得技能的成就反馈，而不是为了区分而一味的难为学生，考察频率低、通用性弱的技能。
也正如前节所述，过多的弱信号、弱策略、窄入口的考察，无法区分学生在某一领域的熟悉度和解决问题的半径，无法区分学生在某一领域内投入精力的多寡，从而为进一步学习或者解决相关问题提供足够的信息依据。
4.4.1 技能考察对技能结构的影响 我们可以假想这样一套考题，
这个考题的覆盖面广，横跨十几个学科，计算机科学，生物学，历史，微积分，地理
而且考察的每一道题，都是在100个需要较长训练时间的技能中随机抽取一个
其难度，是可想而知的，对于一个考生来说，是很难准备这样的一个考试的。
但现实生活中，我们并不会经常遇到这样的场景，但如果考题出的很难，就会变成一个辐射型的技能关系，也就是说一个技能的学习，并不能为你解决另外一个技能提供太多帮助，例如，下图所示的知识结构：
对于这种辐射型的技能，如果每一个点训练时长有限，那么训练的回报率还可以接受。但如果，每一个技能的训练周期很长，就会导致训练的回报率变得很低，会极大地增加学生的挫败感。
但如果命题者，总是考察低频的外环的技能，而不考察中间的可以简化的技能，可以认为是作为命题的一种失误。一来，造成学生备考中的一种混乱，过高的门槛将学生拒之门外，二来，评价缺乏区分度，使得学生要进行大量的训练时长之后，才能体验到学有所成的成就感。但和之前所描述的硬拔式教育相同，虽然对于一个学习能力很强的学生，可能设置这样一个困难的挑战，会加快TA对技能的遍历，但作为一个为普遍学生群体提供内容的教学者来说，这么做是不负责任的。
混乱和随意是不需费力的，但秩序和结构却是要用心和动脑的
对于一个出色的命题，应该对于学生基本技能的掌握有所考察和体现，从基于工具的角度，对基本技能周边可以探索和转化的技能，应当有所侧重，而减少零散的，特例化的技能的考察。如果对考察频率进行分析，绘制出技能的关系图，技能节点间关联度较高的关系图，一个训练回报率合理的技能分布，应该是命题人追求的目标，而不是简单的、粗暴的追求区分，甚至达到了刁难学生的地步。如果想难为学生，并不是一件困难的事；但如何一石多鸟的达到激励、考察和区分的题目，才是需要大量智力投入的。
考试是为了区分能力，不是为了区分分数
对于一个不太出色的命题，会造成评价上的低效，也就是说，无法区分和识别一个掌握了相应技能的学生（算法），有如一个机器学习的测试样本和训练样本相差甚远，那么机器学习所生产出的算法就无法判断其高效性。也就是说，从测试目的出发，测试效率很低。
对于一个考试题目，我们应该对其进行信息量分析。
【案例】低信息量的试题 若 $\ln (x+1) \leqslant ax$， $ab^2 - 2b + 1 = 0$ ，求 $b$
这样一道试题，结合了一元二次方程和导数，但是因为求 $a$ 的本身难度很大，使得这个题目难以识别一个学生是否掌握了一元二次方程。
教育的目的是为了让学习者更高效、更有学习动力的提高自我，粗糙的验收材料，和粗糙的教学材料一样，可能会阻碍教育目的的达到。
对于教学材料的制作和评价，和对验收材料的制作和评价，应该是相对独立进行分析的。
通用能力的考察 未来学习场景的模拟"><link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://yingkui.com/css/dark.css><link rel=stylesheet type=text/css href=https://yingkui.com/css/custom.css><script src=https://yingkui.com/js/main.js></script><link rel=stylesheet href=https://yingkui.com/css/katex.min.css><script defer src=https://yingkui.com/js/katex.min.js></script><script defer src=https://yingkui.com/js/mhchem.min.js></script><script defer src=https://yingkui.com/js/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://yingkui.com/><img src=/logo-ai.jpg alt="Yingkui Lin"></a></div><h1 class=site-title><a href=https://yingkui.com/>Yingkui Lin</a></h1><div class=site-description><p>A Curious Mind.</p><nav class="nav social"><ul class=flat></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Essays</a></li><li><a href=/single>Pages</a></li></ul></nav></div><div class=post><div class=post-header><div class=matter><h1 class=title></h1></div></div><div class=markdown><h2 id=44-对验收材料的改良>4.4 对验收材料的改良</h2><blockquote><p>教学材料的好坏，是在同等算力下，学习者得到的信息值多寡</p></blockquote><blockquote><p>验收材料的好坏，是在同等算法下，测试者得到的信息值多寡</p></blockquote><blockquote><p>不要为了区分，而难为学生；要为了传播知识，而激励学生</p></blockquote><p>对于不同的考试，我们自然并不会使用一样的要求标准。</p><p>对于一个资格性的考试，应该更多的侧重于对必备技能的考察，对知识储备的检测，对关联熟练度的考察。</p><p>对于一个选拔性的考试，尤其是类似中国高考这样，要对学生解决问题的能力进行区分的考试，应当考察学生解决问题中对通用策略的使用，逐步的增加难度，可以是必备技能的一种变形转化，或者是多个技能的结合应用，也可能是一个需要探索尝试的创新情景。</p><p>但与此同时，类似高考这样的考试，有着教学指挥棒的作用，应当为了提高知识的普及率，加大资格性考察的比例，让学生学有所得，有的放矢。可以开源题目库，甚至是开源生成考题的算法，这样的好处，有利于整体学生知识储备和思维能力的改善，而不是为了选拔，放弃了促进整体认知能力提升的功效。</p><p>而本节所谓的改良，就是希望验收材料，要让考生更有信心，有努力的方向，有努力后获得技能的成就反馈，而不是为了区分而一味的难为学生，考察频率低、通用性弱的技能。</p><p>也正如前节所述，过多的弱信号、弱策略、窄入口的考察，无法区分学生在某一领域的熟悉度和解决问题的半径，无法区分学生在某一领域内投入精力的多寡，从而为进一步学习或者解决相关问题提供足够的信息依据。</p><h3 id=441-技能考察对技能结构的影响>4.4.1 技能考察对技能结构的影响</h3><p>我们可以假想这样一套考题，</p><ol><li><p>这个考题的覆盖面广，横跨十几个学科，计算机科学，生物学，历史，微积分，地理</p></li><li><p>而且考察的每一道题，都是在100个需要较长训练时间的技能中随机抽取一个</p></li></ol><p>其难度，是可想而知的，对于一个考生来说，是很难准备这样的一个考试的。</p><p>但现实生活中，我们并不会经常遇到这样的场景，但如果考题出的很难，就会变成一个辐射型的技能关系，也就是说一个技能的学习，并不能为你解决另外一个技能提供太多帮助，例如，下图所示的知识结构：</p><p><img src=../img/radiostruct.svg alt=辐射型技能的关系图></p><p>对于这种辐射型的技能，如果每一个点训练时长有限，那么训练的回报率还可以接受。但如果，每一个技能的训练周期很长，就会导致训练的回报率变得很低，会极大地增加学生的挫败感。</p><p>但如果命题者，总是考察低频的外环的技能，而不考察中间的可以简化的技能，可以认为是作为命题的一种失误。一来，造成学生备考中的一种混乱，过高的门槛将学生拒之门外，二来，评价缺乏区分度，使得学生要进行大量的训练时长之后，才能体验到学有所成的成就感。但和之前所描述的硬拔式教育相同，虽然对于一个学习能力很强的学生，可能设置这样一个困难的挑战，会加快TA对技能的遍历，但作为一个为普遍学生群体提供内容的教学者来说，这么做是不负责任的。</p><blockquote><p>混乱和随意是不需费力的，但秩序和结构却是要用心和动脑的</p></blockquote><p>对于一个出色的命题，应该对于学生基本技能的掌握有所考察和体现，从基于工具的角度，对基本技能周边可以探索和转化的技能，应当有所侧重，而减少零散的，特例化的技能的考察。如果对考察频率进行分析，绘制出技能的关系图，技能节点间关联度较高的关系图，一个训练回报率合理的技能分布，应该是命题人追求的目标，而不是简单的、粗暴的追求区分，甚至达到了刁难学生的地步。如果想难为学生，并不是一件困难的事；但如何一石多鸟的达到激励、考察和区分的题目，才是需要大量智力投入的。</p><blockquote><p>考试是为了区分能力，不是为了区分分数</p></blockquote><p>对于一个不太出色的命题，会造成评价上的低效，也就是说，无法区分和识别一个掌握了相应技能的学生（算法），有如一个机器学习的测试样本和训练样本相差甚远，那么机器学习所生产出的算法就无法判断其高效性。也就是说，从测试目的出发，测试效率很低。</p><p>对于一个考试题目，我们应该对其进行信息量分析。</p><h4 id=案例低信息量的试题>【案例】低信息量的试题</h4><p>若 $\ln (x+1) \leqslant ax$， $ab^2 - 2b + 1 = 0$ ，求 $b$</p><p>这样一道试题，结合了一元二次方程和导数，但是因为求 $a$ 的本身难度很大，使得这个题目难以识别一个学生是否掌握了一元二次方程。</p><p>教育的目的是为了让学习者更高效、更有学习动力的提高自我，粗糙的验收材料，和粗糙的教学材料一样，可能会阻碍教育目的的达到。</p><p><img src=../img/highstruct.svg alt=教学、验收、技能的关系图></p><p>对于教学材料的制作和评价，和对验收材料的制作和评价，应该是相对独立进行分析的。</p><h3 id=通用能力的考察>通用能力的考察</h3><ol><li>未来学习场景的模拟</li></ol></div><div class=tags></div></div></div><div class="footer wrapper"><nav class=nav><div>2025 © Copyright Yingkui.com All Rights Reserved</div></nav></div></body></html>