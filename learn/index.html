<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Cognitive Learning - Yingkui Lin</title><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Cognitive Learning"><meta itemprop=description content="Relations between Topics The reality makes it possible to reduce complexity by compression, and can be expressed in terms of atomic lexemes.
The lexemes have different abstraction levels, complexity levels and utility levels.
The frequence of exposures determines the compression quality and the utility levels of lexemes.
The human cogitive learning is the process of lexemes retention."><meta itemprop=datePublished content="2025-07-04T00:00:00+00:00"><meta itemprop=dateModified content="2025-07-04T00:00:00+00:00"><meta itemprop=wordCount content="1492"><meta property="og:url" content="https://yingkui.com/learn/"><meta property="og:site_name" content="Yingkui Lin"><meta property="og:title" content="Cognitive Learning"><meta property="og:description" content="Relations between Topics The reality makes it possible to reduce complexity by compression, and can be expressed in terms of atomic lexemes.
The lexemes have different abstraction levels, complexity levels and utility levels.
The frequence of exposures determines the compression quality and the utility levels of lexemes.
The human cogitive learning is the process of lexemes retention."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-04T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-04T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Cognitive Learning"><meta name=twitter:description content="Relations between Topics The reality makes it possible to reduce complexity by compression, and can be expressed in terms of atomic lexemes.
The lexemes have different abstraction levels, complexity levels and utility levels.
The frequence of exposures determines the compression quality and the utility levels of lexemes.
The human cogitive learning is the process of lexemes retention."><link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://yingkui.com/css/dark.css><link rel=stylesheet type=text/css href=https://yingkui.com/css/custom.css><script src=https://yingkui.com/js/main.js></script><link rel=stylesheet href=https://yingkui.com/css/katex.min.css><script defer src=https://yingkui.com/js/katex.min.js></script><script defer src=https://yingkui.com/js/mhchem.min.js></script><script defer src=https://yingkui.com/js/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://yingkui.com/><img src=/logo-ai.jpg alt="Yingkui Lin"></a></div><h1 class=site-title><a href=https://yingkui.com/>Yingkui Lin</a></h1><div class=site-description><p>A Curious Mind.</p><nav class="nav social"><ul class=flat></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Essays</a></li><li><a href=/pages>Pages</a></li></ul></nav></div><div class=post><div class=post-header><div class=meta><div class=date><span class=day>04</span>
<span class=rest>Jul 2025</span></div></div><div class=matter><h1 class=title>Cognitive Learning</h1></div></div><div class=markdown><style>strong{font-weight:700;color:#000;background-color:#fff200;padding:0 4px}</style><h2 id=relations-between-topics>Relations between Topics</h2><p><img src=../img/learn.svg alt></p><p>The <strong>reality</strong> makes it possible to reduce complexity by <strong>compression</strong>, and can be expressed in terms of atomic <strong>lexemes</strong>.</p><p>The <strong>lexemes</strong> have different <strong>abstraction levels</strong>, <strong>complexity levels</strong> and <strong>utility levels</strong>.</p><p>The <strong>frequence of exposures</strong> determines the compression quality and the utility levels of lexemes.</p><p>The human <strong>cogitive learning</strong> is the process of lexemes <strong>retention</strong>.</p><p>The goal of education is to have high quality <strong>retentions</strong> in short period for high utility <strong>lexemes</strong>, and this goal relies on high <strong>motivation</strong>.</p><p>The quality of retention is measured by <strong>KL divergence</strong> and influenced by the quality of <strong>training data</strong> and agent <strong>motivation</strong>.</p><p>The motivation level of an agent of changing actions and internal models are described by <strong>Free Energy Principle</strong> (FEP).</p><p>FEP seperates the driven forces into four parts: <strong>Epistemic Gain</strong>, <strong>Cognitive Cost</strong>, <strong>Pragmatic Gain</strong> and <strong>Pragmatic Cost</strong>.</p><p>FEP and cognitive learning is related to physics topics like <strong>thermodynamics</strong> and the <strong>principle of least action</strong>.</p><p>The <strong>intelligence of an agent</strong> is measured by the summation of all its lexeme utility weights for a <strong>skill domain</strong>.</p><p><strong>Spaced repetition</strong> of lexeme exposures leads to a higher rate of retention.</p><p>Some agents might have a higher <strong>rate of retention</strong> using lower exposure count and poorer exposure quality.</p><h2 id=atomic-lexemes>Atomic Lexemes</h2><h3 id=compressed-associations>Compressed Associations</h3><ol><li><strong>$P(t \mid p)$</strong>, given a prompt $p$, the distribution of the generated tokens</li><li>$h^{(l)}_i$, means the $i$-th word (feature) in $l$-th layer of abstraction.</li></ol><p>Markov Blanket as you can assign a symbol to a compression of some class of information.</p><p>redundancy-reduction</p><p>To generalize is to compress, stripped away part of the information you get.</p><p>Learning words is like to add axioms to our internal model of the external worlds, unlike Hilbert&rsquo;s efforts to reduce to a few simple axioms. That is to say that when we try to understand the universe the newton&rsquo;s view is a set of low entropy axioms if we compress the data we observe by ignore the contribution of small variations.</p><p>The reason to compress is:</p><ol><li>it shows up frequently as part of solutions.</li><li>it saves energy, for example, a general rule for many instances and a result of such computation for future usage.</li></ol><h3 id=deep-features>Deep Features</h3><ol><li>If you can&rsquo;t see enough examples, it is hard to mine out a deeper level pattern. The reason is the shallow features also consume you to remember and to memorize.</li></ol><h3 id=causation-features-categorization>Causation. Features. Categorization.</h3><p>Like numbers, we can categorize lexemes be a member of an another lexeme.</p><h3 id=lexemes-properties>Lexemes Properties</h3><ol><li>abstraction level</li><li>utility level</li></ol><h2 id=free-energy-principle>Free Energy Principle</h2><p>The Free Energy Principle is a mathematical framework that explains how biological systems resist disorder and maintain their structure by minimizing free energy.</p>$$
\mathcal{F}[q(s)] = \mathrm{D}_{\mathrm{KL}}\left( q(s) \,\|\, p(s\mid o) \right) - \mathbb{E} _{q(s)} \left[ \log p(o \mid s) \right]
$$<p>The first term relates to complexity, is information-seeking and relates to epistemic value.</p><p>The second term relates to accuracy, is goal-directed behavior and relates to pragmatic value.</p><p>The brain tries to minimize this free energy, and if the system expects a sharp drop in free energy from action $a$, it will treat that action as highly desirable.</p>$$
\text{Motivation}(a) \propto -\mathbb{E}_ {q(s', o' \mid a)}\left[ \mathcal{F}(s', o') \right]
$$<p>We can analyze the motivation as four parts:</p><ol><li><strong>Epistemic Gain</strong>: How informational appealing the situation is. What the percieved epistemic gain (resolving uncertainty, updating its beliefs) is. How curious the agent under this situation.</li><li><strong>Cognitive Cost</strong>: The cognitive cost to reach desired level of resolution. How much efforts needed to obtain the desired information.</li><li><strong>Pragmatic Gain</strong>: The non-intellectual benefits (staying alive, getting food). Get rewarded.</li><li><strong>Pragmatic Cost</strong>: The non-intellectual efforts (workload, spending money).</li></ol><p>Epistemic is much like how bad you want something, and pragmatic is like how much you are willing to sacrifice for this desire.</p><p>The agent might additive to the situation with small investment with high return.</p><p>The beauty of free energy principle is that it allows learning from reality and also makes it possible to manipulate reality for desired states of the learner.</p><p>Most people don&rsquo;t like learning is easily be explained by lack of enough perceived pragmatic gains.</p><p>Minimize surprise (prediction errors) in a resource-constrained, noisy, uncertain world</p><p>Strong bias</p><p>cheap ways to reduce surprise, even if they’re incorrect</p><h2 id=abstract-lexemes>Abstract Lexemes</h2><p>The abstract lexeme is often presented to the agent by a concrete lower level lexeme instance, but without sufficient amount of concrete examples, the agent can&rsquo;t catch the desired lexeme because of ambiguity. By cross validations with several examples, the agent can pin down the feature and make this experience counting for one exposure event.</p><p>For abstract lexemes, the initial encouter is more fragile than a concrete lexeme.</p><h2 id=models>Models</h2><ol><li>$D_{\mathrm{KL}}(T\\|L)$, KL divergence of a learner&rsquo;s probability distribution from a testing set true probability distribution.</li></ol><h2 id=training-data>Training Data</h2><p>$\theta' = \theta - \eta \nabla_\theta \mathcal{L}(f_\theta(x), y)$</p><h2 id=reading-a-learning-material>Reading a Learning Material</h2><p>while reading, people are processing the word one by one and try to make sense from each word, while reading the reader will compress the information by remove much details of the sentences. At the same time, it will also valuate the gains and costs to determine how many interest it will devote to the knowledge.</p><p>Fast searching instead of skill acquisition, illusion of fluency or mastery, epistemic foraging</p><h3 id=zipping-and-unzipping>Zipping and Unzipping</h3><h2 id=retention>Retention</h2><blockquote><p>Repeated exposure to a pattern leads to better retention</p></blockquote><ol><li>$$</li></ol><blockquote><p>High emotional level can increase the retention efficiency in one exposure.</p></blockquote><p>When an agent has a high combined perceived epistemic and pragmatic gain, the agent will open the gate for memorization wider for better retention.</p><p>It can be seen as an analogy for heat transmission, as high energy can permeate deeper. The brain may also revisited the association by replay or self-exposure the event, like a fond memory you active or subconsciously repeatly revisits.</p><p>A well explain video or lecture, only count for a reasonable perceived epistemic gain, not too much shock and not too much randomness or no new information available.</p><p>So that only account for a low level of exposure.</p><p>But by doing exercise, it will increase the agent perceived pragmatic value when the correct answer exposed especially they can see the benefits of solving the problem correctly and the discrepency of required level of resolution of the problem answer.</p><p>The neurals fire together wire together,</p><p>boost synaptic plasticity in the hippocampus and amygdala, noradrenaline and dopamine provide the “tag” that something important happened, acetylcholine focuses encoding resources, and stress hormones fine‑tune consolidation, making surprise or trauma into long‑lasting memories.</p><h3 id=first-few-examples>First Few Examples</h3><h3 id=spaced-repetition>Spaced Repetition</h3><p>The whole idea of efficiency learning is to increase the exposures of high utility associations.</p><p>Greater surprise or informational gain for the learner.</p><p>If the information is presented in a short time of period, that surprise or free energy can be reduced too much.</p><p>as the adjancent occurs will be compressed with little update urgency.</p><h3 id=bad-learners>Bad Learners</h3><p>People tend to abstract ideas from several single instances.</p><h2 id=epistemical-kinetic-energy>Epistemical Kinetic Energy</h2><p>Human is attracted by situations that a low cognitive cost can lead to a boost in knowledge acquisition.</p><h2 id=pragmatical-potential-energy>Pragmatical Potential Energy</h2><h2 id=self-evaluation-as-a-pragmatical-gain>Self-evaluation as a Pragmatical Gain</h2><p>Since people tend to protect their ego and self-worth,</p><h2 id=presumptions>Presumptions</h2><p>I believe:</p><ol><li>all things can be explained by associations.</li><li></li></ol><h2 id=agent>Agent</h2><p>I don&rsquo;t know the cause of these effects, but they are facts observed in reality.</p><blockquote><p>Some agents can achieve desired retention with less exposures.</p></blockquote><p>Some agents can find high abstract associations in a few exposures which we normally call it <strong>insightful</strong>.</p><h2 id=thermodynamics>Thermodynamics</h2>$$
S = \int_{t_1}^{t_2} \underbrace{(T - V)}_{L} \, dt
$$<p>The free energy principle is closely related to the principle of lease action. The Lagrangian is defined as Kinetic energy minus Potential energy.</p><ol><li><strong>Work</strong> is an agent&rsquo;s action to change the environment.</li><li><strong>Entropy</strong> is how confused you are.</li><li><strong>Energy</strong> is how motivated you are.</li><li><strong>Kinetic Energy</strong> is how an agent is epistemically motivated.</li><li><strong>Potential Energy</strong> is how an agent is pragmatically motivated.</li><li>Both low and high entropy systems can be low in complexity. The most interesting, complex systems often lie between pure order and pure randomness.</li></ol><h2 id=learning-as-a-high-return-exploration>Learning as a High Return Exploration</h2><p>There are only solving procedures, but learning is a special type of solving. Even learning with bad materials is like solving problems and by exposing yourself with more useful related contents, which generative ai is super helpful here. It expands the confused part with clear and easy content which might be familiar to the learner.</p><p>Normally, if you do research, you try out new exploration or exploitation current situations.</p><p>But learning in human sense is basically remembering the compressed, high confidence asscociations that is proved to be useful in real world challenges.</p><p>It doesn&rsquo;t matter the association is right or not, maybe the school teachs you the earth is flat, but you don&rsquo;t have the resources to really disproof this.</p><p>There is no system 1 and system 2, it only means fluent words and inarticulate fresh situations.</p><p>repeat at the high utility features, the more abstract feature, the more exposure it needs, and</p><h2 id=tradeoff-of-active-recalls-and-frequent-exposures>Tradeoff of Active Recalls and Frequent Exposures</h2></div><div class=tags></div></div></div><div class="footer wrapper"><nav class=nav><div>2025 © Copyright Yingkui.com All Rights Reserved</div></nav></div></body></html>