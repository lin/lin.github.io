<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>- Yingkui Lin</title><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Yingkui Lin"><meta itemprop=description content="自由能原则 Reward / Utility / Score / Value Surprise / Prediction Error / Chunkify Two Kinds of Predictin Errors Pragmatic or Reward Prediction Error Epistemic or Lexeme Prediction Error But they are the same:
In reinforcement learning or decision theory, the complement of surprise is often called value (or utility).
Low surprise = high expected value (your predictions about the world are confirmed).
High surprise = low value (your model didn’t anticipate what happened)."><meta itemprop=wordCount content="154"><meta property="og:url" content="https://yingkui.com/mv/fep/"><meta property="og:site_name" content="Yingkui Lin"><meta property="og:title" content="Yingkui Lin"><meta property="og:description" content="自由能原则 Reward / Utility / Score / Value Surprise / Prediction Error / Chunkify Two Kinds of Predictin Errors Pragmatic or Reward Prediction Error Epistemic or Lexeme Prediction Error But they are the same:
In reinforcement learning or decision theory, the complement of surprise is often called value (or utility).
Low surprise = high expected value (your predictions about the world are confirmed).
High surprise = low value (your model didn’t anticipate what happened)."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="mv"><meta name=twitter:card content="summary"><meta name=twitter:title content="Yingkui Lin"><meta name=twitter:description content="自由能原则 Reward / Utility / Score / Value Surprise / Prediction Error / Chunkify Two Kinds of Predictin Errors Pragmatic or Reward Prediction Error Epistemic or Lexeme Prediction Error But they are the same:
In reinforcement learning or decision theory, the complement of surprise is often called value (or utility).
Low surprise = high expected value (your predictions about the world are confirmed).
High surprise = low value (your model didn’t anticipate what happened)."><link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://yingkui.com/css/dark.css><link rel=stylesheet type=text/css href=https://yingkui.com/css/custom.css><script src=https://yingkui.com/js/main.js></script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://yingkui.com/><img src=/logo-ai.jpg alt="Yingkui Lin"></a></div><h1 class=site-title><a href=https://yingkui.com/>Yingkui Lin</a></h1><div class=site-description><p>A Curious Mind.</p><nav class="nav social"><ul class=flat></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Essays</a></li><li><a href=/pages>Pages</a></li></ul></nav></div><div class=post><div class=post-header><div class=matter><h1 class=title></h1></div></div><div class=markdown><h2 id=自由能原则>自由能原则</h2><ol><li>Reward / Utility / Score / Value</li><li>Surprise / Prediction Error / Chunkify</li></ol><h3 id=two-kinds-of-predictin-errors>Two Kinds of Predictin Errors</h3><ol><li>Pragmatic or Reward Prediction Error</li><li>Epistemic or Lexeme Prediction Error</li></ol><p>But they are the same:</p><p>In reinforcement learning or decision theory, the complement of surprise is often called value (or utility).</p><p>Low surprise = high expected value (your predictions about the world are confirmed).</p><p>High surprise = low value (your model didn’t anticipate what happened).</p><p>So “optimizing a free-energy bound on surprise or its complement, value” means:</p><p>The brain works to keep its internal model of the world accurate and useful, by reducing prediction error (surprise). This can be phrased either as minimizing surprise (via the free energy bound) or equivalently as maximizing value (the utility of good predictions and actions).</p><h3 id=everything-is-learning-and-testing>Everything is Learning and Testing</h3><ol><li>Mining Lexemes</li><li>Remember Lexemes</li><li>Expect Scores in a testing dataset</li><li>Expect Frequency in a testing dataset</li></ol><h3 id=人生如考试>人生如考试</h3><p>考了哪些知识点，怎么从课本里找到知识点，通过做题细化知识点</p><p>这些知识点都值多少分，哪些知识点考的多，哪些知识点包含在其他知识点里了</p></div><div class=tags></div></div></div><div class="footer wrapper"><nav class=nav><div>2025 © Copyright Yingkui.com All Rights Reserved</div></nav></div></body></html>