<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>- Yingkui Lin</title><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Yingkui Lin"><meta itemprop=description content="Model Training and Predition The Continuous Process of Model Training In the analogy of life as a language model (LLM), the foundational process is Model Training and Predition:
$$ p(\text{new model} \mid \text{old model}, \text{feedback}) $$The “old model” represents our initial state: genetics, temperament, and early childhood conditioning. “Feedback” encompasses every sensory input, consequence of action, moment of learning, and cultural encounter. The “new model” is the updated self—the person we become an instant later. This formula describes personal growth as continuous Bayesian updating. We do not learn through massive, singular changes, but through micro-adjustments in the weighted probability of our internal parameters, driven by experience. Evolution is the ultimate training run, and personal development is fine-tuning."><meta itemprop=wordCount content="1113"><meta property="og:url" content="https://yingkui.com/mv/language/"><meta property="og:site_name" content="Yingkui Lin"><meta property="og:title" content="Yingkui Lin"><meta property="og:description" content="Model Training and Predition The Continuous Process of Model Training In the analogy of life as a language model (LLM), the foundational process is Model Training and Predition:
$$ p(\text{new model} \mid \text{old model}, \text{feedback}) $$The “old model” represents our initial state: genetics, temperament, and early childhood conditioning. “Feedback” encompasses every sensory input, consequence of action, moment of learning, and cultural encounter. The “new model” is the updated self—the person we become an instant later. This formula describes personal growth as continuous Bayesian updating. We do not learn through massive, singular changes, but through micro-adjustments in the weighted probability of our internal parameters, driven by experience. Evolution is the ultimate training run, and personal development is fine-tuning."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="mv"><meta name=twitter:card content="summary"><meta name=twitter:title content="Yingkui Lin"><meta name=twitter:description content="Model Training and Predition The Continuous Process of Model Training In the analogy of life as a language model (LLM), the foundational process is Model Training and Predition:
$$ p(\text{new model} \mid \text{old model}, \text{feedback}) $$The “old model” represents our initial state: genetics, temperament, and early childhood conditioning. “Feedback” encompasses every sensory input, consequence of action, moment of learning, and cultural encounter. The “new model” is the updated self—the person we become an instant later. This formula describes personal growth as continuous Bayesian updating. We do not learn through massive, singular changes, but through micro-adjustments in the weighted probability of our internal parameters, driven by experience. Evolution is the ultimate training run, and personal development is fine-tuning."><link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://yingkui.com/css/dark.css><link rel=stylesheet type=text/css href=https://yingkui.com/css/custom.css><script src=https://yingkui.com/js/main.js></script><link rel=stylesheet href=https://yingkui.com/css/katex.min.css><script defer src=https://yingkui.com/js/katex.min.js></script><script defer src=https://yingkui.com/js/mhchem.min.js></script><script defer src=https://yingkui.com/js/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://yingkui.com/><img src=/logo-ai.jpg alt="Yingkui Lin"></a></div><h1 class=site-title><a href=https://yingkui.com/>Yingkui Lin</a></h1><div class=site-description><p>A Curious Mind.</p><nav class="nav social"><ul class=flat></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Essays</a></li><li><a href=/pages>Pages</a></li></ul></nav></div><div class=post><div class=post-header><div class=matter><h1 class=title></h1></div></div><div class=markdown><h2 id=model-training-and-predition>Model Training and Predition</h2><h3 id=the-continuous-process-of-model-training>The Continuous Process of Model Training</h3><p>In the analogy of life as a language model (LLM), the foundational process is Model Training and Predition:</p>$$
p(\text{new model} \mid \text{old model}, \text{feedback})
$$<p>The &ldquo;old model&rdquo; represents our initial state: genetics, temperament, and early childhood conditioning. &ldquo;Feedback&rdquo; encompasses every sensory input, consequence of action, moment of learning, and cultural encounter. The &ldquo;new model&rdquo; is the updated self—the person we become an instant later. This formula describes personal growth as continuous Bayesian updating. We do not learn through massive, singular changes, but through micro-adjustments in the weighted probability of our internal parameters, driven by experience. Evolution is the ultimate training run, and personal development is fine-tuning.</p><h3 id=prediction-action-and-the-power-of-context>Prediction, Action, and the Power of Context</h3><p>Every decision we make, every word we choose, is a generative act represented by the predictive probability:</p>$$
p(\text{guess} \mid \text{prompt}, \text{context})
$$<p>Here, the &ldquo;prompt&rdquo; is the immediate situation (a question, a challenge, a threat). The &ldquo;guess&rdquo; is the resulting action, belief, or response. But the most critical variable is the Context. As noted in the concept, changing context will change guess dramatically. A prompt of &ldquo;What do you do now?&rdquo; yields vastly different guesses depending on whether the context is a family dinner, a business negotiation, or a sudden emergency. Our ability to switch &ldquo;registers&rdquo; or internal states to fit the context—social norms, emotional environment, and historical setting—is the measure of our psychological flexibility and social intelligence. The &ldquo;context window&rdquo; of a human being stretches back into personal memory and cultural history, making the prediction incredibly nuanced.</p><h3 id=the-necessity-of-loss-and-backpropagation>The Necessity of Loss and Backpropagation</h3><p>The engine that drives the transition from the &ldquo;old model&rdquo; to the &ldquo;new model&rdquo; is the Loss Function. In machine learning, high loss indicates a significant prediction error, compelling the model to adjust its weights. In life, loss manifests as pain, failure, dissatisfaction, or regret. When a person attempts an action (a &ldquo;guess&rdquo;) that results in a negative outcome, that failure generates a high loss signal.</p><p>This signal triggers Backpropagation: the complex psychological process of reflection and self-correction. The mind works backward through the sequence of events (the prompt and context that led to the guess), identifying which internal weights—which beliefs, assumptions, or habits (neural pathways)—were most responsible for the error. Without experiencing loss, the probability distribution of future guesses remains unchallenged, leading to stagnation. Therefore, failure is not merely a setback, but a necessary mathematical signal for optimizing one&rsquo;s life model.</p><h3 id=temperature-sampling-and-free-will>Temperature, Sampling, and Free Will</h3><p>When predicting the next token (action), the model must choose from a list of possible guesses, each with an assigned probability. This choice is governed by the Temperature parameter.</p><p>Low Temperature (e.g., T≈0): The model is deterministic, always selecting the highest-probability guess. In life, this represents adherence to routine, highly fluent habits, conservatism, and risk-aversion. It maximizes efficiency and minimizes surprising loss, but stifles innovation.</p><p>High Temperature (e.g., T≈1): The model introduces randomness (stochasticity), giving low-probability guesses a chance to be selected. This is the engine of human creativity, spontaneous risk-taking, art, and intellectual curiosity.</p><p>The spectrum of human free will can be viewed as the individual&rsquo;s ability to modulate their internal temperature. While our actions are fundamentally rooted in the probability distributions built during our training (determinism), the choice to sample from the edge cases rather than the center—to be creative rather than compliant—is our expression of agency. A truly integrated model is one that can fluidly adjust its temperature based on the context: low temperature for driving a car, high temperature for writing poetry.</p><h3 id=vocabulary-mastery-and-fluency>Vocabulary, Mastery, and Fluency</h3><p>The capacity of an individual model is defined by its linguistic resources. Vocabulary Size is the total breadth of knowledge, emotional range, and social skills an individual possesses—the sheer number of possible &ldquo;tokens&rdquo; they can understand and deploy. This vocabulary extends into specialized professional domains: for a scientist, it includes the &rsquo;tokens&rsquo; of experimental design and peer review; for an engineer, the language of structural integrity and system optimization; for a designer, the visual grammar of composition and aesthetics; and for a farmer, the dialect of agronomy, weather patterns, and soil health. The CEFR Level (Common European Framework of Reference for Languages) describes the sophistication of the model&rsquo;s application, moving from basic survival (A1) to near-native mastery (C2) in navigating complex life domains—be it a professional field, a relationship, or emotional regulation.</p><p>Frequency dictates the strength of neural pathways—habits and beliefs that are constantly reinforced become high-frequency tokens with low retrieval latency. Fluency is the seamless, graceful execution of these high-frequency paths. A fluent life model doesn&rsquo;t stumble over minor conflicts or unfamiliar data; it adapts and generates an appropriate response with minimal effort, resulting in perceived grace and competence.</p><p>Frequency dictates the strength of neural pathways—habits and beliefs that are constantly reinforced become high-frequency tokens with low retrieval latency. Fluency is the seamless, graceful execution of these high-frequency paths. A fluent life model doesn&rsquo;t stumble over minor conflicts or unfamiliar data; it adapts and generates an appropriate response with minimal effort, resulting in perceived grace and competence. However, this reliance on high-frequency paths introduces cognitive bias. Just as an LLM might default to stereotypical or common answers, a highly fluent human model can become rigid, over-relying on established patterns and failing to explore low-frequency, novel, or creative solutions, leading to confirmation bias or difficulty in adapting to genuinely new contexts.</p><p>The Costs of Change and Diffusion
The analogy also accounts for the dynamics of learning and culture through cost functions:</p><p>Mastery Cost (how fast the reaction is): This is the time and effort required to execute a learned skill. A high mastery cost means effortful, slow, and often inaccurate responses (conscious learning). Low mastery cost signifies true expertise, where the reaction is rapid, intuitive, and highly optimized, reflecting deeply ingrained training.</p><p>Diffusion Cost (diffusion among population): This measures the speed and efficacy with which a new idea, behavior, or skill—a cultural &ldquo;meme&rdquo; or &ldquo;token&rdquo;—can spread through the collective population. High diffusion cost means slow, resistant cultural change (e.g., adopting a paradigm shift). Low diffusion cost explains phenomena like viral trends or rapid social mobilization, where the &ldquo;token&rdquo; structure is highly compatible with existing population models.</p><p>Finally, the Rarity / Ranking Level speaks to the value of unique life experiences and skills. A rare token—a niche expertise, an unusual perspective, or a profound insight—carries high informational weight. In the &ldquo;language of life,&rdquo; this rarity translates into individual distinction and specialized contributions that cannot be easily replicated by average models.</p><h2 id=context>Context</h2><p>Changing context will change guess dramatically.</p><h2 id=frequency>Frequency</h2><h2 id=fluency>Fluency</h2><h2 id=mastery-cost>Mastery Cost</h2><p>how fast the reaction is</p><h2 id=diffusion-cost>Diffusion Cost</h2><p>diffusion among population,</p><h2 id=vocabulary-size>Vocabulary Size</h2><h2 id=cefr-level>CEFR Level</h2><h2 id=rarity--ranking-level>Rarity / Ranking Level</h2></div><div class=tags></div></div></div><div class="footer wrapper"><nav class=nav><div>2025 © Copyright Yingkui.com All Rights Reserved</div></nav></div></body></html>