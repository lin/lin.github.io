<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yingkui Lin</title><link>https://yingkui.com/notes/</link><description>Recent content on Yingkui Lin</description><generator>Hugo</generator><language>en-us</language><copyright>© Copyright Yingkui.com All Rights Reserved</copyright><lastBuildDate>Sun, 20 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://yingkui.com/notes/index.xml" rel="self" type="application/rss+xml"/><item><title>Bayes’ Theorem</title><link>https://yingkui.com/notes/bayes/</link><pubDate>Sun, 20 Jul 2025 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/bayes/</guid><description>&lt;p&gt;Imagine a population divided into four groups:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Male, Gamer&lt;/li&gt;
&lt;li&gt;Female, Gamer&lt;/li&gt;
&lt;li&gt;Male, Non-Gamer&lt;/li&gt;
&lt;li&gt;Female, Non-Gamer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We want to know: if a randomly chosen person is male, what is the probability that they are an Gamer?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;By definition,&lt;/p&gt;
$$
 P(\text{Male}\mid \text{Gamer})
 = \frac{\text{number of Male Gamers}}{\text{number of Gamers}}.
 $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similarly,&lt;/p&gt;
$$
 P(\text{Gamer}\mid \text{Male})
 = \frac{\text{number of Male Gamers}}{\text{number of Males}}.
 $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since&lt;/p&gt;
$$
 \text{number of Male Gamers}
 = P(\text{Gamer}\mid \text{Male}) \times \text{number of Males},
 $$&lt;p&gt;we can write&lt;/p&gt;</description></item><item><title>Machine Learning Terms</title><link>https://yingkui.com/notes/ml/</link><pubDate>Sun, 20 Jul 2025 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/ml/</guid><description>&lt;h2&gt;$f(x; \theta)$&lt;/h2&gt;
&lt;h3 id="models-prediction"&gt;Model&amp;rsquo;s Prediction&lt;/h3&gt;
&lt;p&gt;The function $f(x; \theta)$ represents the model&amp;rsquo;s output given input $x$ and parameters $\theta$. It defines how the model maps an input to a prediction.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x$ is the input&lt;/li&gt;
&lt;li&gt;$\theta$ is the model’s parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;br&gt;
If $f(x; \theta) = \theta_1 x + \theta_0$, with $\theta_1 = 2$, $\theta_0 = 1$, and $x = 3$, then:&lt;br&gt;
$f(3; \theta) = 2 \cdot 3 + 1 = 7$&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;$x$&lt;/h2&gt;
&lt;h3 id="input-features"&gt;Input Features&lt;/h3&gt;
&lt;p&gt;$x$ is the input to the model. It can be a scalar, vector, or tensor depending on the task.&lt;/p&gt;</description></item><item><title>Linear Algebra Notes</title><link>https://yingkui.com/notes/la/</link><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/la/</guid><description>&lt;h2 id="vector"&gt;Vector&lt;/h2&gt;
&lt;p&gt;Each vector is an object with many features values.&lt;/p&gt;
&lt;h2 id="matrix"&gt;Matrix&lt;/h2&gt;
&lt;p&gt;Rows are an object with many features, Alice&amp;rsquo;s age gender height weight. Columns are Features for many objects, age of Alice Bob Chris David.&lt;/p&gt;
$$
A = \begin{bmatrix}
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n
\end{bmatrix}
$$&lt;p&gt;$\vec{c}_1, \vec{c}_2, \cdots, \vec{c}_n$ are the base vectors after transformation described in current axis.&lt;/p&gt;
&lt;p&gt;Apply matrix to a vector $\vec{v}$ means you get what $\vec{v}$ means in current axis.&lt;/p&gt;</description></item><item><title/><link>https://yingkui.com/notes/bell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/bell/</guid><description>&lt;h2 id="bells-inequality"&gt;Bell&amp;rsquo;s Inequality&lt;/h2&gt;
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;"&gt;
 &lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/ZuvK-od647c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;h2 id="hidden-variable"&gt;Hidden Variable&lt;/h2&gt;
&lt;h3 id="alice-and-bobs-has-eight-possible-plans"&gt;Alice and Bobs has eight possible plans&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;↑↑↑ &amp;amp; ↓↓↓&lt;/li&gt;
&lt;li&gt;↑↑↓ &amp;amp; ↓↓↑&lt;/li&gt;
&lt;li&gt;↑↓↑ &amp;amp; ↓↑↓&lt;/li&gt;
&lt;li&gt;↑↓↓ &amp;amp; ↓↑↑&lt;/li&gt;
&lt;li&gt;↓↑↑ &amp;amp; ↑↓↓&lt;/li&gt;
&lt;li&gt;↓↑↓ &amp;amp; ↑↓↑&lt;/li&gt;
&lt;li&gt;↓↓↑ &amp;amp; ↑↑↓&lt;/li&gt;
&lt;li&gt;↓↓↓ &amp;amp; ↑↑↑&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="plan-1"&gt;Plan 1&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↓&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="plan-2"&gt;Plan 2&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↑&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="plan-3"&gt;Plan 3&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↓&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="plan-4"&gt;Plan 4&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↑&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="plan-5"&gt;Plan 5&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↓&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="plan-6"&gt;Plan 6&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↓&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↑&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="plan-7"&gt;Plan 7&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↓&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↑&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✗&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="plan-8"&gt;Plan 8&lt;/h3&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 1 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 2 ↑&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Bob 3 ↑&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 1 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 2 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;Alice 3 ↓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;td style="text-align: center"&gt;✓&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are 48 ✓ and 24 ✗ above, total is 8*9 = 72 possibilities.&lt;/p&gt;</description></item><item><title/><link>https://yingkui.com/notes/complexity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/complexity/</guid><description>&lt;h2 id="complexity"&gt;Complexity&lt;/h2&gt;
&lt;h2 id="p"&gt;P&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;PATH(G, s, t) is P. PATH: is there a path between s node and t node in a directed graph G.&lt;/li&gt;
&lt;li&gt;COPRIME(x,y) is P.&lt;/li&gt;
&lt;li&gt;CFG(G, str) is P.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="np-complete"&gt;NP-complete&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;SAT(formula) is NP. Check whether a Boolean formula can return 1.&lt;/li&gt;
&lt;li&gt;SUBSET-SUM(S, target) is NP. Find a set to sum to target.&lt;/li&gt;
&lt;li&gt;HAM_PATH(G, s, t) is NP. A Hamiltonian path in a directed graph G is a directed path that goes through
each node exactly once.&lt;/li&gt;
&lt;li&gt;3SAT(formula) is NP.&lt;/li&gt;
&lt;/ol&gt;
$$
 (x_{1}\lor \lnot x_{2}\lor x_{3})
 \land
 (x_{3}\lor x_{5}\lor \lnot x_{6})
 \land
 (x_{3}\lor \lnot x_{6}\lor x_{4})
 \land
 (\lnot x_{4}\lor x_{5}\lor x_{6})
$$</description></item><item><title/><link>https://yingkui.com/notes/compression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/compression/</guid><description>&lt;h2 id="compression"&gt;Compression&lt;/h2&gt;</description></item><item><title/><link>https://yingkui.com/notes/entropy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/entropy/</guid><description>&lt;h2 id="entropy"&gt;Entropy&lt;/h2&gt;
&lt;h2 id="information"&gt;Information&lt;/h2&gt;
&lt;h2 id="thermodynamics"&gt;Thermodynamics&lt;/h2&gt;</description></item><item><title/><link>https://yingkui.com/notes/info/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/info/</guid><description>&lt;style&gt;
strong {
 font-weight: bold;
 color: black;
 background-color: #fff200;
 padding: 0 4px;
}
&lt;/style&gt;
&lt;h2 id="information-theory"&gt;Information Theory&lt;/h2&gt;
&lt;p&gt;In &lt;strong&gt;Reality&lt;/strong&gt;, High &lt;strong&gt;Frequency&lt;/strong&gt; means high &lt;strong&gt;Compresstion&lt;/strong&gt;, high &lt;strong&gt;Certainty&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Before &lt;strong&gt;Action&lt;/strong&gt;, High &lt;strong&gt;Uncertainty&lt;/strong&gt; means low &lt;strong&gt;Probable&lt;/strong&gt;, high &lt;strong&gt;Entropy&lt;/strong&gt;, high &lt;strong&gt;Work&lt;/strong&gt; to identify.&lt;/p&gt;
&lt;p&gt;After &lt;strong&gt;Action&lt;/strong&gt;, High &lt;strong&gt;Surprise&lt;/strong&gt; means low &lt;strong&gt;Probable&lt;/strong&gt;, high &lt;strong&gt;Information Gain&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Low &lt;strong&gt;Energy&lt;/strong&gt; means high &lt;strong&gt;Probable&lt;/strong&gt;, high &lt;strong&gt;Frequency&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To change &lt;strong&gt;Reality&lt;/strong&gt;, you need to spend energy, change low &lt;strong&gt;Probable&lt;/strong&gt; to high &lt;strong&gt;Probable&lt;/strong&gt;. One action agent provides &lt;strong&gt;Surprise&lt;/strong&gt; to the other non-action agent.&lt;/p&gt;</description></item><item><title/><link>https://yingkui.com/notes/lexemes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/lexemes/</guid><description>&lt;h2 id="lexemes--schemes"&gt;Lexemes &amp;amp; Schemes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Michael Jordan&lt;/li&gt;
&lt;li&gt;Antifragile &amp;amp; Blackswan&lt;/li&gt;
&lt;li&gt;Chess Positions&lt;/li&gt;
&lt;li&gt;Unilever Logo&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="class"&gt;Class&lt;/h2&gt;
$$
\bigl(R\subseteq A\;\wedge\;P(B\mid A,H)\ge1-\varepsilon\bigr)\;\Longrightarrow\;P(B\mid R,H)\ge1-\varepsilon.
$$</description></item><item><title/><link>https://yingkui.com/notes/mechanics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/mechanics/</guid><description>&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;"&gt;
 &lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/MIBfKJHMWHU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;h2 id="newtonian"&gt;Newtonian&lt;/h2&gt;
$$
\vec{F} = \frac{\text d\vec{p}}{\text dt}
$$&lt;h2 id="lagrangian"&gt;Lagrangian&lt;/h2&gt;
$$
L(q_i, \dot q_i, t) \;=\; T(q_i, \dot q_i) \;-\; V(q_i)
$$&lt;p&gt;Kinetic energy minus the potential energy. And Euler–Lagrange equation:&lt;/p&gt;
$$
\frac{d}{dt}\\!\left(\frac{\partial L}{\partial \dot q_i}\right)
\- \frac{\partial L}{\partial q_i}
= 0
$$&lt;h2 id="hamiltionian"&gt;Hamiltionian&lt;/h2&gt;
$$
p_i \;=\; \frac{\partial L}{\partial \dot q_i}
$$$$
H(q_i, p_i, t)
\;=\;
\sum_i p_i\,\dot q_i
\;-\;
L\bigl(q_i,\dot q_i,t\bigr)
$$</description></item><item><title/><link>https://yingkui.com/notes/pa/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/pa/</guid><description>&lt;h2 id="addition"&gt;Addition&lt;/h2&gt;
$$
\begin{aligned}
&amp;\forall x \;f(x, 0 ) =x \newline 
&amp;\forall x \forall y \;f(x, S(y)) = S(f(x, y))
\end{aligned}
$$&lt;h2 id="multiplication"&gt;Multiplication&lt;/h2&gt;
$$
\begin{aligned}
&amp;h(x,0)\;:=\;0\newline 
&amp;h\bigl(x,S(y)\bigr) \;:=\;f\bigl(h(x,y),\,x\bigr)
\end{aligned}
$$&lt;p&gt;Generated by AI.&lt;/p&gt;
&lt;h2 id="statements"&gt;Statements&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Zero is neutral for addition&lt;/strong&gt;&lt;/p&gt;
$$
 \forall x\;\bigl(x + 0 = x\bigr).
 $$&lt;p&gt;&lt;em&gt;Every number plus zero is itself.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Successor distributes over addition&lt;/strong&gt;&lt;/p&gt;
$$
 \forall x\,\forall y\;\bigl(x + S(y) = S(x + y)\bigr).
 $$&lt;p&gt;&lt;em&gt;Adding the successor of $y$ to $x$ is the successor of $(x+y)$.&lt;/em&gt;&lt;/p&gt;</description></item><item><title/><link>https://yingkui.com/notes/politics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/politics/</guid><description>&lt;h2 id="politics"&gt;Politics&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Machiavellianism, Narcissism, and Psychopathy&lt;/li&gt;
&lt;li&gt;checks and balances (legislative, executive, judicial)&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title/><link>https://yingkui.com/notes/pp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/pp/</guid><description>&lt;h2 id="predictive-process"&gt;Predictive Process&lt;/h2&gt;</description></item><item><title/><link>https://yingkui.com/notes/quantum/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/quantum/</guid><description>&lt;h2 id="quantum"&gt;Quantum&lt;/h2&gt;
&lt;p&gt;Imagine you have a group of people from all over the world.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First, you divide them into two groups based on which hemisphere they’re from: the &lt;strong&gt;Northern Hemisphere&lt;/strong&gt; and the &lt;strong&gt;Southern Hemisphere&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Then, you take only the &lt;strong&gt;Northern Hemisphere&lt;/strong&gt; group and split it again into two: those from the &lt;strong&gt;Eastern Hemisphere&lt;/strong&gt; and those from the &lt;strong&gt;Western Hemisphere&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Finally, you take the group from the &lt;strong&gt;Eastern Hemisphere&lt;/strong&gt; (which originally came from the Northern Hemisphere) and split it once more into &lt;strong&gt;Northern Hemisphere&lt;/strong&gt; and &lt;strong&gt;Southern Hemisphere&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now here’s the strange part: in this final split, you somehow end up with &lt;strong&gt;roughly equal numbers of people from the Northern and Southern Hemispheres&lt;/strong&gt;, even though you had already filtered out the Southern Hemisphere in step 1!&lt;/p&gt;</description></item><item><title/><link>https://yingkui.com/notes/web/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/web/</guid><description>&lt;h2 id="web"&gt;Web&lt;/h2&gt;</description></item><item><title>Computation</title><link>https://yingkui.com/notes/computation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/computation/</guid><description>&lt;h2 id="dfa--regular"&gt;DFA / Regular&lt;/h2&gt;
&lt;p&gt;A finite automaton is a 5-tuple&lt;br&gt;
&lt;/p&gt;
$$
M = (Q, \Sigma, \delta, q_{0}, F),
$$&lt;p&gt;&lt;br&gt;
where:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$Q$ is a finite set called the set of states,&lt;/li&gt;
&lt;li&gt;$\Sigma$ is a finite set called the input alphabet,&lt;/li&gt;
&lt;li&gt;$\delta: Q \times \Sigma \to Q$ is the transition function,&lt;/li&gt;
&lt;li&gt;$q_{0}\in Q$ is the start state,&lt;/li&gt;
&lt;li&gt;$F \subseteq Q$ is the set of accepting states.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="nfa--regular"&gt;NFA / Regular&lt;/h2&gt;
&lt;p&gt;A nondeterministic finite automaton is a 5-tuple&lt;br&gt;
&lt;/p&gt;</description></item><item><title>Free Energy Principle</title><link>https://yingkui.com/notes/fep/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/fep/</guid><description>&lt;h2 id="the-free-energy-principle"&gt;The Free Energy Principle&lt;/h2&gt;
$$
a, \mu, m = \arg\min F(\tilde{s}, \mu \mid m)
$$&lt;p&gt;Where:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$F(\tilde{s}, \mu \mid m)$ is the variational free energy, a quantity that bounds surprise.&lt;/li&gt;
&lt;li&gt;$\tilde{s}$: sensory inputs (possibly generalized coordinates of sensations).&lt;/li&gt;
&lt;li&gt;$\mu$: internal states (like beliefs or expectations).&lt;/li&gt;
&lt;li&gt;$m$: the model or structure used to generate predictions.&lt;/li&gt;
&lt;li&gt;$a$: actions that can influence the sensory input.&lt;/li&gt;
&lt;li&gt;$\arg\min$: denotes the values of $a, \mu, m$ that minimize the free energy.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This means that an agent (e.g. a brain) is constantly trying to:&lt;/p&gt;</description></item><item><title>Hopfield Networks Example</title><link>https://yingkui.com/notes/hopfield/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/hopfield/</guid><description>&lt;p&gt;&lt;em&gt;Generated from GPT-4o&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It converges to a stable situation that is pre-defined.&lt;/p&gt;
&lt;h2 id="step-by-step-example"&gt;Step-by-Step Example&lt;/h2&gt;
&lt;p&gt;Let’s say we want to store &lt;strong&gt;two 4-bit patterns&lt;/strong&gt;:&lt;/p&gt;
$$
\text{Pattern A: } \xi^1 = [+1, -1, +1, -1] \newline
\text{Pattern B: } \xi^2 = [-1, +1, -1, +1]
$$&lt;h3 id="step-1-compute-the-weight-matrix"&gt;Step 1: Compute the Weight Matrix&lt;/h3&gt;
&lt;p&gt;Using the Hebbian learning rule:&lt;/p&gt;
$$
w_{ij} = \frac{1}{N} \sum_{\mu=1}^P \xi_i^\mu \xi_j^\mu \quad \text{for } i \ne j
$$&lt;p&gt;Here, $N = 4$, $P = 2$&lt;/p&gt;</description></item></channel></rss>