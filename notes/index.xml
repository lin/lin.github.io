<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yingkui Lin</title><link>https://yingkui.com/notes/</link><description>Recent content on Yingkui Lin</description><generator>Hugo</generator><language>en-us</language><copyright>© Copyright Yingkui.com All Rights Reserved</copyright><lastBuildDate>Sun, 20 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://yingkui.com/notes/index.xml" rel="self" type="application/rss+xml"/><item><title>Bayes’ Theorem</title><link>https://yingkui.com/notes/bayes/</link><pubDate>Sun, 20 Jul 2025 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/bayes/</guid><description>&lt;p>Imagine a population divided into four groups:&lt;/p>
&lt;ol>
&lt;li>Male, Gamer&lt;/li>
&lt;li>Female, Gamer&lt;/li>
&lt;li>Male, Non-Gamer&lt;/li>
&lt;li>Female, Non-Gamer&lt;/li>
&lt;/ol>
&lt;p>We want to know: if a randomly chosen person is male, what is the probability that they are an Gamer?&lt;/p>
&lt;ol>
&lt;li>
&lt;p>By definition,&lt;/p>
$$
 P(\text{Male}\mid \text{Gamer})
 = \frac{\text{number of Male Gamers}}{\text{number of Gamers}}.
 $$&lt;/li>
&lt;li>
&lt;p>Similarly,&lt;/p>
$$
 P(\text{Gamer}\mid \text{Male})
 = \frac{\text{number of Male Gamers}}{\text{number of Males}}.
 $$&lt;/li>
&lt;li>
&lt;p>Since&lt;/p>
$$
 \text{number of Male Gamers}
 = P(\text{Gamer}\mid \text{Male}) \times \text{number of Males},
 $$&lt;p>we can write&lt;/p></description></item><item><title>Machine Learning Terms</title><link>https://yingkui.com/notes/ml/</link><pubDate>Sun, 20 Jul 2025 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/ml/</guid><description>&lt;h2 id="fx-theta">$f(x; \theta)$&lt;/h2>
&lt;h3 id="models-prediction">Model&amp;rsquo;s Prediction&lt;/h3>
&lt;p>The function $f(x; \theta)$ represents the model&amp;rsquo;s output given input $x$ and parameters $\theta$. It defines how the model maps an input to a prediction.&lt;/p>
&lt;ul>
&lt;li>$x$ is the input&lt;/li>
&lt;li>$\theta$ is the model’s parameters&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Example:&lt;/strong>&lt;br>
If $f(x; \theta) = \theta_1 x + \theta_0$, with $\theta_1 = 2$, $\theta_0 = 1$, and $x = 3$, then:&lt;br>
$f(3; \theta) = 2 \cdot 3 + 1 = 7$&lt;/p>
&lt;hr>
&lt;h2 id="x">$x$&lt;/h2>
&lt;h3 id="input-features">Input Features&lt;/h3>
&lt;p>$x$ is the input to the model. It can be a scalar, vector, or tensor depending on the task.&lt;/p></description></item><item><title>Linear Algebra Notes</title><link>https://yingkui.com/notes/la/</link><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/la/</guid><description>&lt;h2 id="vector">Vector&lt;/h2>
&lt;p>Each vector is an object with many features values.&lt;/p>
&lt;h2 id="matrix">Matrix&lt;/h2>
&lt;p>Rows are an object with many features, Alice&amp;rsquo;s age gender height weight. Columns are Features for many objects, age of Alice Bob Chris David.&lt;/p>
$$
A = \begin{bmatrix}
\vec{c}_1 &amp; \vec{c}_2 &amp; \cdots &amp; \vec{c}_n
\end{bmatrix}
$$&lt;p>$\vec{c}_1, \vec{c}_2, \cdots, \vec{c}_n$ are the base vectors after transformation described in current axis.&lt;/p>
&lt;p>Apply matrix to a vector $\vec{v}$ means you get what $\vec{v}$ means in current axis.&lt;/p></description></item><item><title/><link>https://yingkui.com/notes/bell/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/bell/</guid><description>&lt;h2 id="bells-inequality">Bell&amp;rsquo;s Inequality&lt;/h2>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
 &lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/ZuvK-od647c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
 &lt;/div>

&lt;h2 id="hidden-variable">Hidden Variable&lt;/h2>
&lt;h3 id="alice-and-bobs-has-eight-possible-plans">Alice and Bobs has eight possible plans&lt;/h3>
&lt;ol>
&lt;li>↑↑↑ &amp;amp; ↓↓↓&lt;/li>
&lt;li>↑↑↓ &amp;amp; ↓↓↑&lt;/li>
&lt;li>↑↓↑ &amp;amp; ↓↑↓&lt;/li>
&lt;li>↑↓↓ &amp;amp; ↓↑↑&lt;/li>
&lt;li>↓↑↑ &amp;amp; ↑↓↓&lt;/li>
&lt;li>↓↑↓ &amp;amp; ↑↓↑&lt;/li>
&lt;li>↓↓↑ &amp;amp; ↑↑↓&lt;/li>
&lt;li>↓↓↓ &amp;amp; ↑↑↑&lt;/li>
&lt;/ol>
&lt;h3 id="plan-1">Plan 1&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↓&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↑&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↑&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↑&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="plan-2">Plan 2&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↑&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↑&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↑&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="plan-3">Plan 3&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↓&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↑&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↑&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="plan-4">Plan 4&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↑&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↑&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="plan-5">Plan 5&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↓&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↑&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↑&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="plan-6">Plan 6&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↓&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↑&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↑&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="plan-7">Plan 7&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↓&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↑&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✗&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="plan-8">Plan 8&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th style="text-align: center">&lt;/th>
 &lt;th style="text-align: center">Bob 1 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 2 ↑&lt;/th>
 &lt;th style="text-align: center">Bob 3 ↑&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td style="text-align: center">Alice 1 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 2 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td style="text-align: center">Alice 3 ↓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;td style="text-align: center">✓&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;p>There are 48 ✓ and 24 ✗ above, total is 8*9 = 72 possibilities.&lt;/p></description></item><item><title/><link>https://yingkui.com/notes/complexity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/complexity/</guid><description>&lt;h2 id="complexity">Complexity&lt;/h2>
&lt;h2 id="p">P&lt;/h2>
&lt;ol>
&lt;li>PATH(G, s, t) is P. PATH: is there a path between s node and t node in a directed graph G.&lt;/li>
&lt;li>COPRIME(x,y) is P.&lt;/li>
&lt;li>CFG(G, str) is P.&lt;/li>
&lt;/ol>
&lt;h2 id="np-complete">NP-complete&lt;/h2>
&lt;ol>
&lt;li>SAT(formula) is NP. Check whether a Boolean formula can return 1.&lt;/li>
&lt;li>SUBSET-SUM(S, target) is NP. Find a set to sum to target.&lt;/li>
&lt;li>HAM_PATH(G, s, t) is NP. A Hamiltonian path in a directed graph G is a directed path that goes through
each node exactly once.&lt;/li>
&lt;li>3SAT(formula) is NP.&lt;/li>
&lt;/ol>
$$
 (x_{1}\lor \lnot x_{2}\lor x_{3})
 \land
 (x_{3}\lor x_{5}\lor \lnot x_{6})
 \land
 (x_{3}\lor \lnot x_{6}\lor x_{4})
 \land
 (\lnot x_{4}\lor x_{5}\lor x_{6})
$$</description></item><item><title/><link>https://yingkui.com/notes/compression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/compression/</guid><description>&lt;h2 id="compression">Compression&lt;/h2></description></item><item><title/><link>https://yingkui.com/notes/info/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/info/</guid><description>&lt;style>
strong {
 font-weight: bold;
 color: black;
 background-color: #fff200;
 padding: 0 4px;
}
&lt;/style>
&lt;h2 id="information-theory">Information Theory&lt;/h2>
&lt;p>In &lt;strong>Reality&lt;/strong>, High &lt;strong>Frequency&lt;/strong> means high &lt;strong>Compresstion&lt;/strong>, high &lt;strong>Certainty&lt;/strong>.&lt;/p>
&lt;p>Before &lt;strong>Action&lt;/strong>, High &lt;strong>Uncertainty&lt;/strong> means low &lt;strong>Probable&lt;/strong>, high &lt;strong>Entropy&lt;/strong>, high &lt;strong>Work&lt;/strong> to identify.&lt;/p>
&lt;p>After &lt;strong>Action&lt;/strong>, High &lt;strong>Surprise&lt;/strong> means low &lt;strong>Probable&lt;/strong>, high &lt;strong>Information Gain&lt;/strong>.&lt;/p>
&lt;p>Low &lt;strong>Energy&lt;/strong> means high &lt;strong>Probable&lt;/strong>, high &lt;strong>Frequency&lt;/strong>.&lt;/p>
&lt;p>To change &lt;strong>Reality&lt;/strong>, you need to spend energy, change low &lt;strong>Probable&lt;/strong> to high &lt;strong>Probable&lt;/strong>. One action agent provides &lt;strong>Surprise&lt;/strong> to the other non-action agent.&lt;/p></description></item><item><title/><link>https://yingkui.com/notes/lexemes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/lexemes/</guid><description>&lt;h2 id="lexemes--schemes">Lexemes &amp;amp; Schemes&lt;/h2>
&lt;ol>
&lt;li>Michael Jordan&lt;/li>
&lt;li>Antifragile &amp;amp; Blackswan&lt;/li>
&lt;li>Chess Positions&lt;/li>
&lt;li>Unilever Logo&lt;/li>
&lt;/ol>
&lt;h2 id="class">Class&lt;/h2>
$$
\bigl(R\subseteq A\\;\wedge\\;P(B\mid A,H)\ge1-\varepsilon\bigr)\\;\Longrightarrow\\;P(B\mid R,H)\ge1-\varepsilon.
$$</description></item><item><title/><link>https://yingkui.com/notes/mechanics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/mechanics/</guid><description>&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
 &lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/MIBfKJHMWHU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
 &lt;/div>

&lt;h2 id="newtonian">Newtonian&lt;/h2>
$$
\vec{F} = \frac{\text d\vec{p}}{\text dt}
$$&lt;h2 id="lagrangian">Lagrangian&lt;/h2>
$$
L(q_i, \dot q_i, t) \\;=\\; T(q_i, \dot q_i) \\;-\\; V(q_i)
$$&lt;p>Kinetic energy minus the potential energy. And Euler–Lagrange equation:&lt;/p>
$$
\frac{d}{dt}\\!\left(\frac{\partial L}{\partial \dot q_i}\right)
\- \frac{\partial L}{\partial q_i}
= 0
$$&lt;h2 id="hamiltionian">Hamiltionian&lt;/h2>
$$
p_i \\;=\\; \frac{\partial L}{\partial \dot q_i}
$$$$
H(q_i, p_i, t)
\\;=\\;
\sum_i p_i\\,\dot q_i
\\;-\\;
L\bigl(q_i,\dot q_i,t\bigr)
$$</description></item><item><title/><link>https://yingkui.com/notes/pa/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/pa/</guid><description>&lt;h2 id="addition">Addition&lt;/h2>
$$
\begin{aligned}
&amp;\forall x \\;f(x, 0 ) =x \newline 
&amp;\forall x \forall y \\;f(x, S(y)) = S(f(x, y))
\end{aligned}
$$&lt;h2 id="multiplication">Multiplication&lt;/h2>
$$
\begin{aligned}
&amp;h(x,0)\\;:=\\;0\newline 
&amp;h\bigl(x,S(y)\bigr) \\;:=\\;f\bigl(h(x,y),\\,x\bigr)
\end{aligned}
$$&lt;p>Generated by AI.&lt;/p>
&lt;h2 id="statements">Statements&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Zero is neutral for addition&lt;/strong>&lt;/p>
$$
 \forall x\;\bigl(x + 0 = x\bigr).
 $$&lt;p>&lt;em>Every number plus zero is itself.&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Successor distributes over addition&lt;/strong>&lt;/p>
$$
 \forall x\,\forall y\;\bigl(x + S(y) = S(x + y)\bigr).
 $$&lt;p>&lt;em>Adding the successor of $y$ to $x$ is the successor of $(x+y)$.&lt;/em>&lt;/p></description></item><item><title/><link>https://yingkui.com/notes/politics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/politics/</guid><description>&lt;h2 id="politics">Politics&lt;/h2>
&lt;ol>
&lt;li>Machiavellianism, Narcissism, and Psychopathy&lt;/li>
&lt;li>checks and balances (legislative, executive, judicial)&lt;/li>
&lt;/ol></description></item><item><title/><link>https://yingkui.com/notes/pp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/pp/</guid><description>&lt;h2 id="predictive-process">Predictive Process&lt;/h2></description></item><item><title/><link>https://yingkui.com/notes/quantum/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/quantum/</guid><description>&lt;h2 id="quantum">Quantum&lt;/h2>
&lt;p>Imagine you have a group of people from all over the world.&lt;/p>
&lt;ol>
&lt;li>First, you divide them into two groups based on which hemisphere they’re from: the &lt;strong>Northern Hemisphere&lt;/strong> and the &lt;strong>Southern Hemisphere&lt;/strong>.&lt;/li>
&lt;li>Then, you take only the &lt;strong>Northern Hemisphere&lt;/strong> group and split it again into two: those from the &lt;strong>Eastern Hemisphere&lt;/strong> and those from the &lt;strong>Western Hemisphere&lt;/strong>.&lt;/li>
&lt;li>Finally, you take the group from the &lt;strong>Eastern Hemisphere&lt;/strong> (which originally came from the Northern Hemisphere) and split it once more into &lt;strong>Northern Hemisphere&lt;/strong> and &lt;strong>Southern Hemisphere&lt;/strong>.&lt;/li>
&lt;/ol>
&lt;p>Now here’s the strange part: in this final split, you somehow end up with &lt;strong>roughly equal numbers of people from the Northern and Southern Hemispheres&lt;/strong>, even though you had already filtered out the Southern Hemisphere in step 1!&lt;/p></description></item><item><title/><link>https://yingkui.com/notes/web/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/web/</guid><description>&lt;h2 id="web">Web&lt;/h2></description></item><item><title>Computation</title><link>https://yingkui.com/notes/computation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/computation/</guid><description>&lt;h2 id="dfa--regular">DFA / Regular&lt;/h2>
&lt;p>A finite automaton is a 5-tuple&lt;br>
&lt;/p>
$$
M = (Q, \Sigma, \delta, q_{0}, F),
$$&lt;p>&lt;br>
where:&lt;/p>
&lt;ol>
&lt;li>$Q$ is a finite set called the set of states,&lt;/li>
&lt;li>$\Sigma$ is a finite set called the input alphabet,&lt;/li>
&lt;li>$\delta: Q \times \Sigma \to Q$ is the transition function,&lt;/li>
&lt;li>$q_{0}\in Q$ is the start state,&lt;/li>
&lt;li>$F \subseteq Q$ is the set of accepting states.&lt;/li>
&lt;/ol>
&lt;h2 id="nfa--regular">NFA / Regular&lt;/h2>
&lt;p>A nondeterministic finite automaton is a 5-tuple&lt;br>
&lt;/p></description></item><item><title>Free Energy Principle</title><link>https://yingkui.com/notes/fep/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/fep/</guid><description>&lt;h2 id="the-free-energy-principle">The Free Energy Principle&lt;/h2>
$$
a, \mu, m = \arg\min F(\tilde{s}, \mu \mid m)
$$&lt;p>Where:&lt;/p>
&lt;ol>
&lt;li>$F(\tilde{s}, \mu \mid m)$ is the variational free energy, a quantity that bounds surprise.&lt;/li>
&lt;li>$\tilde{s}$: sensory inputs (possibly generalized coordinates of sensations).&lt;/li>
&lt;li>$\mu$: internal states (like beliefs or expectations).&lt;/li>
&lt;li>$m$: the model or structure used to generate predictions.&lt;/li>
&lt;li>$a$: actions that can influence the sensory input.&lt;/li>
&lt;li>$\arg\min$: denotes the values of $a, \mu, m$ that minimize the free energy.&lt;/li>
&lt;/ol>
&lt;p>This means that an agent (e.g. a brain) is constantly trying to:&lt;/p></description></item><item><title>Hopfield Networks Example</title><link>https://yingkui.com/notes/hopfield/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yingkui.com/notes/hopfield/</guid><description>&lt;p>&lt;em>Generated from GPT-4o&lt;/em>&lt;/p>
&lt;p>It converges to a stable situation that is pre-defined.&lt;/p>
&lt;h2 id="step-by-step-example">Step-by-Step Example&lt;/h2>
&lt;p>Let’s say we want to store &lt;strong>two 4-bit patterns&lt;/strong>:&lt;/p>
$$
\text{Pattern A: } \xi^1 = [+1, -1, +1, -1] \newline
\text{Pattern B: } \xi^2 = [-1, +1, -1, +1]
$$&lt;h3 id="step-1-compute-the-weight-matrix">Step 1: Compute the Weight Matrix&lt;/h3>
&lt;p>Using the Hebbian learning rule:&lt;/p>
$$
w_{ij} = \frac{1}{N} \sum_{\mu=1}^P \xi_i^\mu \xi_j^\mu \quad \text{for } i \ne j
$$&lt;p>Here, $N = 4$, $P = 2$&lt;/p></description></item></channel></rss>