<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Linear Algebra Notes - Yingkui Lin</title><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Linear Algebra Notes"><meta itemprop=description content="Vector Each vector is an object with many features values.
Matrix Rows are an object with many features, Alice’s age gender height weight. Columns are Features for many objects, age of Alice Bob Chris David.
$$ A = \begin{bmatrix} \vec{c}_1 & \vec{c}_2 & \cdots & \vec{c}_n \end{bmatrix} $$
$\vec{c}_1, \vec{c}_2, \cdots, \vec{c}_n$ are the base vectors after transformation described in current axis.
Apply matrix to a vector $\vec{v}$ means you get what $\vec{v}$ means in current axis."><meta itemprop=datePublished content="2025-06-16T00:00:00+00:00"><meta itemprop=dateModified content="2025-06-16T00:00:00+00:00"><meta itemprop=wordCount content="269"><meta property="og:url" content="https://yingkui.com/notes/la/"><meta property="og:site_name" content="Yingkui Lin"><meta property="og:title" content="Linear Algebra Notes"><meta property="og:description" content="Vector Each vector is an object with many features values.
Matrix Rows are an object with many features, Alice’s age gender height weight. Columns are Features for many objects, age of Alice Bob Chris David.
$$ A = \begin{bmatrix} \vec{c}_1 & \vec{c}_2 & \cdots & \vec{c}_n \end{bmatrix} $$
$\vec{c}_1, \vec{c}_2, \cdots, \vec{c}_n$ are the base vectors after transformation described in current axis.
Apply matrix to a vector $\vec{v}$ means you get what $\vec{v}$ means in current axis."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2025-06-16T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-16T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Linear Algebra Notes"><meta name=twitter:description content="Vector Each vector is an object with many features values.
Matrix Rows are an object with many features, Alice’s age gender height weight. Columns are Features for many objects, age of Alice Bob Chris David.
$$ A = \begin{bmatrix} \vec{c}_1 & \vec{c}_2 & \cdots & \vec{c}_n \end{bmatrix} $$
$\vec{c}_1, \vec{c}_2, \cdots, \vec{c}_n$ are the base vectors after transformation described in current axis.
Apply matrix to a vector $\vec{v}$ means you get what $\vec{v}$ means in current axis."><link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://yingkui.com/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://yingkui.com/css/dark.css><link rel=stylesheet type=text/css href=https://yingkui.com/css/custom.css><script src=https://yingkui.com/js/main.js></script><link rel=stylesheet href=https://yingkui.com/css/katex.min.css><script defer src=https://yingkui.com/js/katex.min.js></script><script defer src=https://yingkui.com/js/mhchem.min.js></script><script defer src=https://yingkui.com/js/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://yingkui.com/><img src=/logo-ai.jpg alt="Yingkui Lin"></a></div><h1 class=site-title><a href=https://yingkui.com/>Yingkui Lin</a></h1><div class=site-description><p>A Curious Mind.</p><nav class="nav social"><ul class=flat></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Essays</a></li><li><a href=/pages>Pages</a></li></ul></nav></div><div class=post><div class=post-header><div class=meta><div class=date><span class=day>16</span>
<span class=rest>Jun 2025</span></div></div><div class=matter><h1 class=title>Linear Algebra Notes</h1></div></div><div class=markdown><h2 id=vector>Vector</h2><p>Each vector is an object with many features values.</p><h2 id=matrix>Matrix</h2><p>Rows are an object with many features, Alice&rsquo;s age gender height weight. Columns are Features for many objects, age of Alice Bob Chris David.</p><p>$$
A = \begin{bmatrix}
\vec{c}_1 & \vec{c}_2 & \cdots & \vec{c}_n
\end{bmatrix}
$$</p><p>$\vec{c}_1, \vec{c}_2, \cdots, \vec{c}_n$ are the base vectors after transformation described in current axis.</p><p>Apply matrix to a vector $\vec{v}$ means you get what $\vec{v}$ means in current axis.</p><p>So $A$ is information in current, $\vec{v}$ is information in transformed, $A\vec{v}$ is information in current.</p><p>So $\vec{v}$ is <code>hola</code> and $A\vec{v}$ is <code>hello</code>.</p><p>$$
A = U\Sigma V^{T}
$$</p><p>So any matrix is: Rotate → Scale → Rotate</p><p>It means that we transform information to something we are familiar with, to somewhere many fluent tools are available, then goes back to another encoding system.</p><h2 id=determinate>Determinate</h2><p>$$
\det(A) = \prod_{i=1}^{n} \lambda_i
$$</p><p>determinant tells you how much a matrix scales space</p><p>if $\det(A)=0$, the transformation will squish all of the space into a lower dimension. This means some information is destroyed in the process. And some of the axis are redundant information.</p><p>All columns are linearly independent.</p><h2 id=inverse>Inverse</h2><p>$$\mathrm{rank}(A) = n$$</p><h2 id=rank>Rank</h2><h2 id=non-square>Non-square</h2><p>$$A \in \mathbb{R}^{m \times n}, \quad B \in \mathbb{R}^{p \times q}$$</p><p>the number of columns in $A$ must equal the number of rows in $B$, that is.</p><p>$$
n = p
$$</p><p>and then</p><p>$$
AB \in \mathbb{R}^{m \times q}
$$</p><h2 id=eigenvector>Eigenvector</h2><p>$$
A\vec{v} = \lambda \vec{v}
$$</p><p>A pure rotation matrix doesn&rsquo;t have eigenvectors.</p><p>$$
\text{det}(A -\lambda I) = 0
$$</p><p>so it squish to a lower dimension.</p></div><div class=tags></div></div></div><div class="footer wrapper"><nav class=nav><div>2025 © Copyright Yingkui.com All Rights Reserved</div></nav></div></body></html>